# Media Analytics Pipeline

## Overview

This project implements a media analytics pipeline for analyzing campaign performance data from various platforms. The pipeline generates several visual reports, providing insights into metrics such as impressions, clicks, and views across different device types and platforms. The reports are accessible via a FastAPI-based web service and are generated using Docker.

The pipeline includes:
1. Data aggregation and analysis of campaign performance data from multiple platforms.
2. Weekly impressions reporting with normalization for partial weeks.
3. Various visualizations and summary reports.

## Requirements

- Docker (to run the pipeline in a containerized environment)
- FastAPI (for the web service API)
- Uvicorn (for serving the FastAPI application)
- Pandas and other relevant libraries for data processing
- Media Analytics Pipeline logic (custom code)

## Setup and Installation

1. **Clone the repository:**

   ```bash
   git clone https://github.com/your-username/media-analytics-pipeline.git
   cd media-analytics-pipeline
   ```

2. **Build the Docker container:**

   Ensure you have Docker installed on your machine. In the project directory, build the Docker image:

   ```bash
   docker build -t media-analytics .
   ```

3. **Run the Docker container:**

   After building the image, you can run the container with the following command:

   ```bash
   docker run -d \
     -p 8000:8000 \
     -v "$(pwd)/data:/app/data" \
     -v "$(pwd)/output:/app/output" \
     --name analytics \
     media-analytics
   ```

   - This command maps the local `data` directory to `/app/data` and the `output` directory to `/app/output` inside the container.
   - The container will run the FastAPI application on port 8000.

## Running the Pipeline

Once the container is running, you can trigger the pipeline execution through the FastAPI web service.

### To execute the pipeline:

Use the following `curl` command to trigger the pipeline:

```bash
curl -X 'POST' \
  'http://localhost:8000/run-pipeline' \
  -H 'accept: application/json' \
  -d ''
```

### To download a generated report:

Once the pipeline execution is complete and the reports are generated, you can download them by specifying the filename:

```bash
curl -X 'GET' \
  'http://localhost:8000/download-report/{filename}' \
  -H 'accept: application/json'
```

For example, to download the `Video_Completions_by_Device_Type_and_Platform.html` report:

```bash
curl -X 'GET' \
  'http://localhost:8000/download-report/Video_Completions_by_Device_Type_and_Platform.html' \
  -H 'accept: application/json'
```

### Available Reports

The following reports are generated by the pipeline:

- `CTR_by_Platform.html`
- `Impressions_Over_Time_by_Platform.html`
- `Total_Impressions_by_Platform.html`
- `Video_Completion_Metrics_by_Platform.html`
- `Video_Completions_by_Device_Type_and_Platform.html`
- `meta_weekly_impressions.csv`
- `total_impressions_by_week.html`
- `weekly_impressions_by_duration.html`

## Directory Structure

- `data/`: Directory for input data files.
- `output/`: Directory where generated reports will be saved.
- `api.py`: FastAPI server for handling requests.
- `Dockerfile`: Docker setup for the pipeline and FastAPI application.
- `media_analytics_pipeline.py`: The main code for the analytics pipeline.
- `requirements.txt`: List of Python dependencies (if applicable).

## Troubleshooting

- **Error: Report not found.**  
  Ensure the pipeline is executed first via the `/run-pipeline` endpoint before attempting to download reports.

- **Error: Pipeline execution failed.**  
  Check the logs for any error messages during pipeline execution. You can view the logs using:

  ```bash
  docker logs -f analytics
  ```
